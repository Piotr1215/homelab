apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: opentelemetry-collector
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"  # Deploy after Tempo
spec:
  project: default
  source:
    chart: opentelemetry-collector
    repoURL: https://open-telemetry.github.io/opentelemetry-helm-charts
    targetRevision: 0.97.1
    helm:
      values: |
        # Deployment mode
        mode: deployment
        replicaCount: 1

        # Image configuration
        image:
          repository: otel/opentelemetry-collector-k8s

        # OpenTelemetry Collector configuration
        config:
          receivers:
            # OTLP receiver - primary protocol for OpenTelemetry
            otlp:
              protocols:
                grpc:
                  endpoint: 0.0.0.0:4317
                http:
                  endpoint: 0.0.0.0:4318

            # Jaeger receiver - for Jaeger-compatible clients
            jaeger:
              protocols:
                grpc:
                  endpoint: 0.0.0.0:14250
                thrift_http:
                  endpoint: 0.0.0.0:14268
                thrift_compact:
                  endpoint: 0.0.0.0:6831

            # Zipkin receiver - for Zipkin-compatible clients
            zipkin:
              endpoint: 0.0.0.0:9411

          processors:
            # Batch processor - improves performance
            batch:
              timeout: 10s
              send_batch_size: 1024

            # Memory limiter - prevents OOM
            memory_limiter:
              check_interval: 1s
              limit_percentage: 80
              spike_limit_percentage: 25

          exporters:
            # Export to Tempo
            otlp:
              endpoint: tempo.tempo.svc.cluster.local:4317
              tls:
                insecure: true

            # Export metrics to Prometheus (optional)
            prometheus:
              endpoint: 0.0.0.0:8889

          service:
            pipelines:
              # Traces pipeline
              traces:
                receivers: [otlp, jaeger, zipkin]
                processors: [memory_limiter, batch]
                exporters: [otlp]

        # Service configuration
        service:
          type: ClusterIP

        # ServiceMonitor for Prometheus metrics
        serviceMonitor:
          enabled: true
          extraLabels:
            release: kube-prometheus-stack

        # Resource limits
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        # Pod annotations
        podAnnotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "8889"

  destination:
    server: https://kubernetes.default.svc
    namespace: tempo

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
